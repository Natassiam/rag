### Summary

The implemented system is a Retrieval-Augmented Generation (RAG) application, named Norma, designed to answer questions about academic regulations based on information extracted from PDF documents. By integrating multiple technologies, vector embeddings, and a database, the system provides contextual search and response generation. The graphical interface, developed using Streamlit, ensures accessibility for all users. The system can process large volumes of unstructured data (PDFs). PostgreSQL, with the pgvector extension, enables vector similarity operations, essential for efficient semantic search.

1. Components and Technologies Used

1.1 Data Processing

The system utilizes the pdfplumber library to extract text from PDFs. After extraction, texts are processed to ensure semantic cohesion and divided into "chunks" (text pieces) using regular expressions that identify sentence boundaries. This approach ensures that the blocks stored in the database represent complete ideas, improving search accuracy and response generation.

1.2 Database

The PostgreSQL database is configured to support vector storage and search via the pgvector extension. The table structure includes columns for title, textual content, and 768-dimensional embedding vectors. These dimensions match the embeddings generated by Google's Generative AI embedding model. The system automatically creates the table and extension if necessary.

1.3 Embeddings and Models

The Google Generative AI library, models/embedding-001, generates embeddings for both documents and user queries. These embeddings transform textual information into numerical representations, enabling semantic similarity evaluation between user questions and stored documents. Additionally, the Gemini API, specifically the gemini-1.5-flash model, generates responses. It is configured with moderate temperature (0.5) to balance creativity and accuracy. The model supports an input token limit of 1,048,576 and an output limit of 8,192 tokens.

1.4 Semantic Search

Upon receiving a query, the system generates a vector for the question and uses it to search for similar documents in the database. Vector similarity metrics, using Cosine Distance, rank documents based on semantic proximity to the query. Only the most relevant documents (top-k) are passed to the response generation model, ensuring high-quality information.

1.5 Response Generation

With the retrieved documents, the system uses LangChain's QA model to construct detailed answers. A custom prompt was designed to prioritize contextual information and return clear answers, translating them into Portuguese when necessary. If no relevant information is found, a standard message informs the user that no response is available.

1.6 User Interface

The graphical interface was implemented using Streamlit, enabling interactivity through a simple and user-friendly interface. Users can:

Upload multiple PDF files.

Enter questions directly into the system.

View generated responses along with source references.

Additionally, the interface provides informative messages during data processing, keeping users aware of system operations.

2. Experiments

2.1 File Adjustments

Adjusted to support the upload of multiple documents.

2.2 Language Model Adjustment

Tested Llama and Gemini-Flash language models. The Gemini-Flash provided the best responses.

Adjusted prompt and context size to 768 tokens for improved response accuracy and lower latency.

2.3 Evaluation Adjustments

Installed evaluation libraries for RAG systems.

Tested RAGAS tool but encountered errors in Streamlit and metric calculations, along with high latency. Final evaluation used Cosine Similarity.

2.4 Chunk Size Adjustments

Tested chunk sizes between 10 to 50. Larger chunks led to poorer semantic responses. Final size set to 20, yielding the best results.

3. Workflow

3.1 Upload and Indexing

The user uploads one or more PDFs containing academic regulations.

The system processes the PDFs, extracts text, splits it into meaningful blocks, and generates embeddings.

Embeddings are stored in the database along with corresponding text and titles.

3.2 Query and Response

The user enters a question into the text field in the interface.

The system generates an embedding for the question and searches for the most relevant documents.

Based on the retrieved documents, the generation model constructs a detailed response.

The response is displayed along with a list of referenced sources.

4. Evaluation

Cosine Similarity: Evaluates the similarity between the model-generated response and the expected answer (e.g., using embeddings). Higher similarity values indicate more accurate responses. This metric calculates the similarity between the query and the response.

5. System Strengths

Complete Automation: From database creation to response generation, all steps are automated, minimizing manual intervention.

Efficient Search: The combination of vector embeddings and pgvector enables fast and accurate searches, even for large data volumes.

Intuitive Interface: Streamlit's simplicity ensures ease of use for all users, regardless of technical background.

Contextual Responses: Advanced generative models guarantee relevant and comprehensible answers, meeting user needs.
